{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kle-hauzenberg/assignment5-xlstm/blob/main/A5_Hauzenberger_COLAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUFNk0BJAMZH"
      },
      "source": [
        "# Assignment 5: Extended Long Short-Term Memory (xLSTM)\n",
        "\n",
        "*Author:* Philipp Seidl\n",
        "\n",
        "*Copyright statement:* This  material,  no  matter  whether  in  printed  or  electronic  form,  may  be  used  for  personal  and non-commercial educational use only.  Any reproduction of this manuscript, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors.\n",
        "\n",
        "In this assignment, we will explore the xLSTM architecture, a novel extension of the classic LSTM model. The paper can be found here: https://arxiv.org/abs/2405.04517"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBfgx3oEAc3W"
      },
      "source": [
        "## Background\n",
        "Recurrent Neural Networks (RNNs), particularly LSTMs, have proven highly effective in various sequence modeling tasks. However, the emergence of Transformers, with their parallel processing capabilities, has shifted the focus away from LSTMs, especially in large-scale language modeling.\n",
        "The xLSTM architecture aims to bridge this gap by enhancing LSTMs with mechanisms inspired by modern LLMs (e.g. block-strucutre, residual connections, ...).  Further it introduces:\n",
        "- Exponential gating with normalization and stabilization techniques, which improves gradient flow and memory capacity.\n",
        "- Modifications to the LSTM memory structure, resulting in two variants:\n",
        "    - sLSTM: Employs a scalar memory with a scalar update rule and a new memory mixing technique through recurrent connections.\n",
        "    - mLSTM: Features a matrix memory, employs a covariance update rule, and is fully parallelizable, making it suitable for scaling.\n",
        "\n",
        "By integrating these extensions into residual block backbones, xLSTM blocks are formed, which can then be residually stacked to create complete xLSTM architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08ut_E9kAdpU"
      },
      "source": [
        "## Exercise 1: Environment Setup\n",
        "\n",
        "When working with new architectures or specialized frameworks, it's essential to correctly set up the environment to ensure reproducability. This exercise focuses on setting up the environment for working with the `xlstm` repository.\n",
        "\n",
        "1. Visit and clone the official repository: [https://github.com/NX-AI/xlstm](https://github.com/NX-AI/xlstm).  \n",
        "2. Set up the environment  \n",
        "3. Document your setup:  \n",
        "   - OS, Python version, Environment setup, CUDA version (if applicable), and GPU details.  \n",
        "   - Note any challenges you faced and how you resolved them.\n",
        "4. Submit your setup as a bash script using the IPython `%%bash` magic. Ensure it is reproducible.\n",
        "\n",
        "Getting mLSTM working only is fine (if you encounter issues with sLSTM cuda kernels)\n",
        "\n",
        "> **Note**: Depending on your system setup, you may need to adjust the `environment_pt220cu121.yaml` file, such as for the CUDA version. For this assignment, it is recommended to run it on GPUs. If you don't have one, consider using  [Colab](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true) or other online resources.\n",
        "\n",
        "> **Recommendations**: While the repository suggests using `conda`, we recommend using `mamba` or `micromamba` instead (way faster) (except if you are using colab). Learn more about them here: [https://mamba.readthedocs.io/en/latest/index.html](https://mamba.readthedocs.io/en/latest/index.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdb5fIMaKea1",
        "outputId": "a083df27-2610-43d4-f135-af165f3ae1ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/NX-AI/xlstm@79e463c84cd8bb839bb9a7d81138f1a0184c68a1\n",
            "  Cloning https://github.com/NX-AI/xlstm (to revision 79e463c84cd8bb839bb9a7d81138f1a0184c68a1) to /tmp/pip-req-build-jtuf74rr\n",
            "  Resolved https://github.com/NX-AI/xlstm to commit 79e463c84cd8bb839bb9a7d81138f1a0184c68a1\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.2)\n",
            "Requirement already satisfied: dacite in /usr/local/lib/python3.10/dist-packages (1.8.1)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.3)\n",
            "Cloning the data repository...\n",
            "  Repository already exists. Skip cloning.\n",
            "Documenting environment setup...\n",
            "Setup complete. Details logged in /content/assignment5-xlstm/environment_setup.txt.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "# Install the specific version of xlstm directly from GitHub\n",
        "pip install git+https://github.com/NX-AI/xlstm@79e463c84cd8bb839bb9a7d81138f1a0184c68a1 2>/dev/null\n",
        "\n",
        "# Install additional required packages directly into Colab\n",
        "pip install omegaconf\n",
        "pip install dacite\n",
        "pip install torchmetrics\n",
        "pip install ninja\n",
        "\n",
        "# Clone the GitHub repository that includes the data and the database of\n",
        "# hyperparameter experiments\n",
        "DATA_REPO_URL=\"https://github.com/kle-hauzenberg/assignment5-xlstm.git\"\n",
        "DATA_REPO_NAME=\"assignment5-xlstm\"\n",
        "echo \"Cloning the data repository...\"\n",
        "if [ -d \"$DATA_REPO_NAME\" ]; then\n",
        "    echo \"  Repository already exists. Skip cloning.\"\n",
        "else\n",
        "    git clone $DATA_REPO_URL $DATA_REPO_NAME 2>/dev/null\n",
        "fi\n",
        "\n",
        "# Documenting environment details\n",
        "echo \"Documenting environment setup...\"\n",
        "OS=$(uname -s)\n",
        "PYTHON=$(python --version)\n",
        "GPU=$(system_profiler SPDisplaysDataType 2>/dev/null | grep \"Chip\" || echo \"No GPU detected\")\n",
        "\n",
        "FILENAME=\"/content/assignment5-xlstm/environment_setup.txt\"\n",
        "echo -e \"Environment setup details:\\n\" > \"$FILENAME\"\n",
        "echo \"Operating System: $OS\" >> \"$FILENAME\"\n",
        "echo \"Python Version: $PYTHON\" >> \"$FILENAME\"\n",
        "echo \"GPU Details: $GPU\" >> \"$FILENAME\"\n",
        "\n",
        "wait\n",
        "echo \"Setup complete. Details logged in \"$FILENAME\".\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FejZLBoK_Lo",
        "outputId": "1afaf4c9-d3d9-4716-aa50-c578ff294d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=64', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module slstm_HS64BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:546: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, training, *inputs):\n",
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:571: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_s):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Verify your installation of xLSTM:\n",
        "from omegaconf import OmegaConf\n",
        "from dacite import from_dict\n",
        "from dacite import Config as DaciteConfig\n",
        "from xlstm import xLSTMBlockStack, xLSTMBlockStackConfig\n",
        "import os\n",
        "import torch\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "use_slstm_kernels = True # set to True if you want to check if sLSTM cuda kernels are working\n",
        "\n",
        "xlstm_cfg = f\"\"\"\n",
        "mlstm_block:\n",
        "  mlstm:\n",
        "    conv1d_kernel_size: 4\n",
        "    qkv_proj_blocksize: 4\n",
        "    num_heads: 4\n",
        "slstm_block:\n",
        "  slstm:\n",
        "    backend: {'cuda' if use_slstm_kernels else 'vanilla'}\n",
        "    num_heads: 4\n",
        "    conv1d_kernel_size: 4\n",
        "    bias_init: powerlaw_blockdependent\n",
        "  feedforward:\n",
        "    proj_factor: 1.3\n",
        "    act_fn: gelu\n",
        "context_length: 32\n",
        "num_blocks: 2 #7\n",
        "embedding_dim: 64\n",
        "slstm_at: [1] # empty = mLSTM only\n",
        "\"\"\"\n",
        "cfg = OmegaConf.create(xlstm_cfg)\n",
        "cfg = from_dict(data_class=xLSTMBlockStackConfig, data=OmegaConf.to_container(cfg),\n",
        "                config=DaciteConfig(strict=True))\n",
        "xlstm_stack = xLSTMBlockStack(cfg)\n",
        "\n",
        "x = torch.randn(4, 32, 64).to(DEVICE)\n",
        "xlstm_stack = xlstm_stack.to(DEVICE)\n",
        "y = xlstm_stack(x)\n",
        "y.shape == x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbkUQdktAkeG"
      },
      "source": [
        "## Exercise 2: Understanding xLSTM Hyperparameters\n",
        "Explain key hyperparameters that influence the performance and behavior of the xLSTM architecture and explain how they influence total parameter count.\n",
        "The explanation should include: proj_factor, num_heads, act_fn, context_length, num_blocks, embedding_dim, hidden_size, dropout, slstm_at, qkv_proj_blocksize, conv1d_kernel_size. Also include how the matrix memory size of mLSTM is determined.\n",
        "\n",
        "To get a better grasp of the xLSTM architecture, I rewrite its equation in vectorized from with a focus on the dimensions of the cell inputs, the (learnable) weight matices and other parameters, and the cell outputs. Another focus is on the additional features that are not directly part of the sub-architectures of the mLSTM and sLSTM blocks: normalization, post and pre up-projection, convolution layers.\n",
        "\n",
        "**Layer normalization.** We apply layer normalization at different places in the model. First, on the inputs to each mLSTM and sLSTM layer. The size of the inputs are defined by the embedding dimension (which encodes semantic information about input elements). Second, but here I am not precise, after each mLSTM and sLSTM cell and after a xLSTM block (just want to mention it here for completness sake). In every case, each layer normalization has **two trainable parameters** (scale and shift).\n",
        "\n",
        "The **sLSTM** in vectorized form with input tensor $\\mathbf{x}_t$:\n",
        "$$\\begin{align*}\n",
        "\\tilde{\\mathbf{x}}_t &= \\theta\\left((\\mathbf{x}_t,\\mathbf{x}_{t-1},\\ldots\\mathbf{x}_{t-p})\\mathbf{w}_x\\right) & \\text{causal convolution with }p\\text{ lags: }(D\\times 1)  \\\\\n",
        "\\mathbf{z}_t &= \\varphi\\left(\\mathbf{W}_z\\tilde{\\mathbf{x}}_t + \\mathbf{R}_z\\mathbf{h}_{t-1} + \\mathbf{b}_z \\right) & \\text{cell input: }(D\\times 1) \\\\\n",
        "\\mathbf{i}_t &= \\exp\\left(\\mathbf{W}_i\\tilde{\\mathbf{x}}_t + \\mathbf{R}_i\\mathbf{h}_{t-1} + \\mathbf{b}_i \\right) & \\text{input gate: }(D\\times 1) \\\\\n",
        "\\mathbf{f}_t &= \\sigma\\left(\\mathbf{W}_f\\tilde{\\mathbf{x}}_t + \\mathbf{R}_f\\mathbf{h}_{t-1} + \\mathbf{b}_f \\right) & \\text{forget gate: }(D\\times 1) \\\\\n",
        "\\mathbf{o}_t &= \\sigma\\left(\\mathbf{W}_o\\tilde{\\mathbf{x}}_t + \\mathbf{R}_o\\mathbf{h}_{t-1} + \\mathbf{b}_o \\right) & \\text{output gate: }(D\\times 1) \\\\\n",
        "\\mathbf{c}_t &= \\mathbf{f}_t \\odot \\mathbf{c}_{t-1} + \\mathbf{i}_t \\odot \\mathbf{z}_t  & \\text{cell state: }(D\\times 1)\\\\\n",
        "\\mathbf{n}_t &= \\mathbf{f}_t \\odot \\mathbf{n}_{t-1} + \\mathbf{i}_t & \\text{normalizer state: }(D\\times 1) \\\\\n",
        "\\mathbf{h}_t &= \\mathbf{o}_t \\odot \\left(\\mathbf{c}_t \\odot \\mathbf{n}_t^{-1}\\right) & \\text{hidden state: }(D\\times 1)\n",
        "\\end{align*}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4rSyOdnAv6r"
      },
      "source": [
        "## Exercise 3: Train an xLSTM model on the Trump Dataset from the previous exercise\n",
        "Your task is to train an xLSTM model on the Trump Dataset from the previous exercise.\n",
        "- The goal is to achieve an average validation loss $\\mathcal{L}_{\\text{val}} < 1.35$.\n",
        "- You do not need to perform an extensive hyperparameter search, but you should document your runs. Log your runs with used hyperparameters using tools like wandb, neptune, mlflow, ... or a similar setup. Log training/validation loss and learning rate over steps as well as total trainable parameters of the model for each run.\n",
        "- You can use the training setup from the previous exercises or any setup of your choice using high level training libaries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchmetrics\n",
        "import torchmetrics.classification as classification\n",
        "from dacite import from_dict\n",
        "from xlstm.xlstm_lm_model import xLSTMLMModel, xLSTMLMModelConfig\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "from torchmetrics import Metric\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import time\n",
        "import pickle\n",
        "import sqlite3\n",
        "\n",
        "class Encoder:\n",
        "    def __init__(self, alphabet: str):\n",
        "        # Define the alphabet and create a mapping from characters to integers and back\n",
        "        self.alphabet = alphabet\n",
        "        self.char_to_idx = {char: idx for idx, char in enumerate(alphabet)}\n",
        "        self.idx_to_char = {idx: char for idx, char in enumerate(alphabet)}\n",
        "        # Build the regex pattern from the alphabet\n",
        "        self.regex = f\"[^{re.escape(alphabet)}]\"\n",
        "\n",
        "    def __call__(self, input_data):\n",
        "        if isinstance(input_data, str):\n",
        "            # Make everything lower case, remove characters not in the alphabet, and\n",
        "            # concatenate characters not using a separator (i.e. \"\".join())\n",
        "            filtered_data = input_data.lower()\n",
        "            # Replace all unknown chars with \" \"\n",
        "            filtered_data = re.sub(self.regex, \" \", filtered_data)\n",
        "            # Reduce multiple blanks to one\n",
        "            filtered_data = re.sub(\" +\", \" \", filtered_data)\n",
        "            # Convert the filtered data to a list of indexes and encode (to 64-bit integers,\n",
        "            # typically used for indexes)\n",
        "            indexes = [self.char_to_idx[char] for char in filtered_data]\n",
        "            encoded = torch.tensor(indexes, dtype=torch.long)\n",
        "            return encoded\n",
        "\n",
        "        elif isinstance(input_data, torch.Tensor):\n",
        "            # Decode the tensor of indexes back into a string\n",
        "            decoded = \"\".join(self.idx_to_char[idx.item()] for idx in input_data)\n",
        "            return decoded\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Input must be either a string or a torch.Tensor.\")\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, file_name: str, seq_length: int, encoder):\n",
        "        \"\"\"\n",
        "        Loads and prepares a text dataset for training a neural network.\n",
        "\n",
        "        Args:\n",
        "        - file_name (str): File name on Google drive.\n",
        "        - seq_length, l (int): Length of one sample sequence (plus one\n",
        "            as we split the sequence in inputs and targets).\n",
        "        - vocab: The alphabet.\n",
        "        \"\"\"\n",
        "        self.seq_length = seq_length\n",
        "        self.encoder = encoder\n",
        "\n",
        "        # Read the file and use the encoder to filter and encode the text\n",
        "        try:\n",
        "            with open(file_name, 'r') as f:\n",
        "                raw_text = f.read()\n",
        "        except FileNotFoundError:\n",
        "            response = requests.get(file_name)\n",
        "            if response.status_code == 200:\n",
        "                raw_text = response.text\n",
        "            else:\n",
        "                raise FileNotFoundError(\"File not found or failed to fetch.\")\n",
        "        self.text = self.encoder(raw_text).tolist()\n",
        "\n",
        "        self.num_sequences = len(self.text) // (self.seq_length+1)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the total number of sequences in the dataset.\n",
        "        \"\"\"\n",
        "        return self.num_sequences\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns a single sequence as a torch.Tensor when the class TextDataset\n",
        "        is accessed using square bracket notation.\n",
        "\n",
        "        Args:\n",
        "        - idx (int): Index of the sequence.\n",
        "\n",
        "        Returns:\n",
        "        - torch.tensor representing the sequences.\n",
        "        \"\"\"\n",
        "        if idx < 0 or idx >= self.num_sequences:\n",
        "            raise IndexError(\"Index out of range\")\n",
        "\n",
        "        start = idx * self.seq_length\n",
        "        end = start + self.seq_length+1\n",
        "        sequence = self.text[start:end]\n",
        "\n",
        "        return torch.tensor(sequence, dtype=torch.long)\n",
        "\n",
        "\n",
        "class VocabularyAccuracy(Metric):\n",
        "    def __init__(self, vocab_size, average=\"weighted\"):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self._acc = classification.MulticlassAccuracy(num_classes=self.vocab_size, average=average)\n",
        "\n",
        "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
        "        preds = preds.reshape((-1, preds.shape[-1]))\n",
        "        target = target.flatten()\n",
        "        return self._acc.update(preds, target)\n",
        "\n",
        "    def compute(self):\n",
        "        return self._acc.compute().item()\n",
        "\n",
        "\n",
        "class ExperimentLogger:\n",
        "    def __init__(self):\n",
        "        self.results = []\n",
        "\n",
        "    def log(self, step: int, lr, train_loss, val_loss=None, val_acc=None):\n",
        "        self.results.append({\n",
        "            \"Step\": step,\n",
        "            \"Learning rate\": lr,\n",
        "            \"Training loss\": train_loss,\n",
        "            \"Validation loss\": val_loss,\n",
        "            \"Accuracy\": val_acc\n",
        "        })\n",
        "\n",
        "    def to_dataframe(self):\n",
        "        return pd.DataFrame(self.results)\n",
        "\n",
        "\n",
        "class ExperimentDatabase:\n",
        "    def __init__(self, db_name: str=\"experiment_results.db\"):\n",
        "        self.db_name = db_name\n",
        "        self._create_tables()\n",
        "\n",
        "    def _create_tables(self):\n",
        "        with sqlite3.connect(self.db_name) as conn:\n",
        "            conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS experiments (\n",
        "                experiment_id TEXT PRIMARY KEY,\n",
        "                config BLOB\n",
        "            )\n",
        "            \"\"\")\n",
        "            conn.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS steps (\n",
        "                experiment_id TEXT,\n",
        "                Step INTEGER,\n",
        "                \"Learning rate\" REAL,\n",
        "                \"Training loss\" REAL,\n",
        "                \"Validation loss\" REAL,\n",
        "                Accuracy REAL,\n",
        "                FOREIGN KEY(experiment_id) REFERENCES experiments(experiment_id)\n",
        "            )\n",
        "            \"\"\")\n",
        "\n",
        "    def insert_experiment(self, config, stats, experiment_id: str=\"debugging\"):\n",
        "        # Serialize configuration of experiment\n",
        "        config_blob = pickle.dumps(config)\n",
        "\n",
        "        with sqlite3.connect(self.db_name) as conn:\n",
        "            # Check if the experiment_id already exists\n",
        "            isexperiment = conn.execute(\"SELECT 1 FROM experiments WHERE experiment_id = ?\",\n",
        "                                        (experiment_id,)).fetchone()\n",
        "            if isexperiment:\n",
        "                conn.execute(\"DELETE FROM experiments WHERE experiment_id = ?\", (experiment_id,))\n",
        "                conn.execute(\"DELETE FROM steps WHERE experiment_id = ?\", (experiment_id,))\n",
        "\n",
        "            # Insert experiment-level parameters\n",
        "            conn.execute(\"INSERT INTO experiments (experiment_id, config) VALUES (?, ?)\",\n",
        "                         (experiment_id, config_blob))\n",
        "\n",
        "            # Insert step-level statistics\n",
        "            stats[\"experiment_id\"] = experiment_id\n",
        "            stats.to_sql(\"steps\", conn, if_exists=\"append\", index=False)\n",
        "\n",
        "    def query_experiment(self, experiment_id: str):\n",
        "        with sqlite3.connect(self.db_name) as conn:\n",
        "            # Fetch configuration of experiment\n",
        "            config = conn.execute(\"SELECT config FROM experiments WHERE experiment_id = ?\",\n",
        "                                  (experiment_id,)).fetchone()\n",
        "            if not config:\n",
        "                print(f\"No experiment with ID {experiment_id} does exist.\")\n",
        "                return None\n",
        "\n",
        "            config = pickle.loads(config[0])\n",
        "\n",
        "            # Fetch statistics per step\n",
        "            steps = pd.read_sql_query(\"SELECT * FROM steps WHERE experiment_id = ?\",\n",
        "                                       conn, params=(experiment_id,))\n",
        "        # Combine into a hierarchical structure\n",
        "        result = {}\n",
        "        result[experiment_id] = {\n",
        "            \"config\": config,\n",
        "            \"steps\": steps.to_dict(orient=\"records\")\n",
        "        }\n",
        "        return result\n",
        "\n",
        "    def query_all(self):\n",
        "        with sqlite3.connect(self.db_name) as conn:\n",
        "            # Fetch all experiments and steps\n",
        "            experiments = pd.read_sql_query(\"SELECT * FROM experiments\", conn)\n",
        "            steps = pd.read_sql_query(\"SELECT * FROM steps\", conn)\n",
        "\n",
        "        # Combine into a hierarchical structure\n",
        "        result = {}\n",
        "        for _, experiment in experiments.iterrows():\n",
        "            experiment_id = experiment[\"experiment_id\"]\n",
        "            config = pickle.loads(experiment[\"config\"])\n",
        "            result[experiment_id] = {\n",
        "                \"config\": config,\n",
        "                \"steps\": steps[steps[\"experiment_id\"] == experiment_id].to_dict(orient=\"records\")\n",
        "            }\n",
        "        return result\n",
        "\n",
        "    def list_experiments(self):\n",
        "        with sqlite3.connect(self.db_name) as conn:\n",
        "            experiments = pd.read_sql_query(\"SELECT * FROM experiments\", conn)\n",
        "\n",
        "        experiments[\"config\"] = experiments[\"config\"].apply(pickle.loads)\n",
        "\n",
        "        # Extract and print information for each experiments\n",
        "        print(\"List of experiments:\")\n",
        "        print(\"-\" * 50)\n",
        "        for _, experiment in experiments.iterrows():\n",
        "            experiment_id = experiment[\"experiment_id\"]\n",
        "            config = experiment[\"config\"]\n",
        "\n",
        "            # Extract model name and description from config\n",
        "            model_name = config.get(\"model\", {}).get(\"name\", \"N/A\")\n",
        "            model_description = config.get(\"model\", {}).get(\"description\", \"N/A\")\n",
        "\n",
        "            print(f\"Experiment ID: {experiment_id}\")\n",
        "            print(f\"  Model: {model_name}\")\n",
        "            print(f\"  Description: {model_description}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "\n",
        "def plot3_train_val_loss(title, experiment_ids, legend_text, db):\n",
        "    # Create 3-by-1 subplot for three different models, classes, etc.\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    fig.suptitle(title)\n",
        "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
        "\n",
        "    # Iterate over experiment groups and generate subplots\n",
        "    for idx_mdl, experiment_group in enumerate(experiment_ids):\n",
        "        ax = axes[idx_mdl]\n",
        "        for idx_exp, experiment_id in enumerate(experiment_group):\n",
        "            results = db.query_experiment(experiment_id)\n",
        "            if results is None:\n",
        "                continue\n",
        "            config = results[experiment_id][\"config\"]\n",
        "            steps = pd.DataFrame(results[experiment_id][\"steps\"])\n",
        "\n",
        "            # Check wheter required data are available in database\n",
        "            if \"Step\" not in steps or \"Training loss\" not in steps or \"Validation loss\" not in steps:\n",
        "                print(f\"Experiment {experiment_id} is missing required data.\")\n",
        "                continue\n",
        "\n",
        "            # Plot training and validation losses\n",
        "            legend_text_resolved = legend_text.format(**locals())\n",
        "            ax.plot(steps[\"Step\"], steps[\"Training loss\"],\n",
        "                    linestyle=\"--\", color=colors[idx_exp])\n",
        "            if idx_mdl == 0:\n",
        "                ax.plot(steps[\"Step\"], steps[\"Validation loss\"],\n",
        "                        linestyle=\"-\", color=colors[idx_exp],\n",
        "                        label=legend_text_resolved)\n",
        "                ax.legend()\n",
        "            else:\n",
        "                ax.plot(steps[\"Step\"], steps[\"Validation loss\"],\n",
        "                        linestyle=\"-\", color=colors[idx_exp])\n",
        "\n",
        "        ax.set_title(f\"{config.model.name}\")\n",
        "        ax.set_xlabel(\"Step\")\n",
        "        ax.set_ylabel(\"Loss\")\n",
        "\n",
        "    # Adjust layout and show the plot\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hRkWZQK1wK3n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up configuration\n",
        "xlstm_cfg = \"\"\"\n",
        "training:\n",
        "  seed: 42\n",
        "  batch_size: 256\n",
        "  lr: 0.01\n",
        "  lr_warmup_steps: 100\n",
        "  lr_decay_until_steps: ${.num_steps}\n",
        "  lr_min: 0.00001\n",
        "  weight_decay: 0.1\n",
        "  dropout: 0\n",
        "  num_steps: 1500\n",
        "  val_every_step: 30\n",
        "  device: \"cpu\"\n",
        "\n",
        "model:\n",
        "  name: \"xLSTM[1:1]\"\n",
        "  description: \"default parameterization\"\n",
        "  num_blocks: 2\n",
        "  embedding_dim: 128\n",
        "  mlstm_block:\n",
        "    mlstm:\n",
        "        proj_factor: 2\n",
        "        conv1d_kernel_size: 4\n",
        "        qkv_proj_blocksize: 4\n",
        "        num_heads: 4\n",
        "  slstm_block:\n",
        "    slstm:\n",
        "      backend: \"vanilla\"\n",
        "      conv1d_kernel_size: 4\n",
        "      num_heads: 4\n",
        "    feedforward:\n",
        "      proj_factor: 1.3\n",
        "      act_fn: gelu\n",
        "  slstm_at: [1]\n",
        "  context_length: 64\n",
        "  vocab_size: ${dataset.vocab_size}\n",
        "\n",
        "dataset:\n",
        "  vocab: \"abcdefghijklmnopqrstuvwxyz0123456789 .!?\"\n",
        "  vocab_size: ${len:${.vocab}}\n",
        "  file_train: \"assignment5-xlstm/trump_train.txt\"\n",
        "  file_valid: \"assignment5-xlstm/trump_val.txt\"\n",
        "\n",
        "database:\n",
        "  name: \"assignment5-xlstm/hyperparameter_experiments.db\"\n",
        "\"\"\"\n",
        "# Create new resolver in OmegaConf\n",
        "if not(OmegaConf.has_resolver(\"len\")):\n",
        "    OmegaConf.register_new_resolver(\"len\", lambda x: len(x))\n",
        "\n",
        "cfg = OmegaConf.create(xlstm_cfg)\n",
        "OmegaConf.resolve(cfg)\n",
        "\n",
        "# Set device and overwrite default \"cpu\" if either \"cuda\" or \"mps\" is available\n",
        "if torch.cuda.is_available():\n",
        "    cfg.training.device = \"cuda\"\n",
        "    cfg.model.slstm_block.slstm.backend = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    cfg.training.device = \"mps\""
      ],
      "metadata": {
        "id": "h52_T9ZzwPmK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(cfg, model, logger):\n",
        "    torch.manual_seed(cfg.training.seed)\n",
        "\n",
        "    # Instantiate training and validation data\n",
        "    train_data = TextDataset(cfg.dataset.file_train, cfg.model.context_length, Encoder(cfg.dataset.vocab))\n",
        "    train_loader = DataLoader(train_data, batch_size=cfg.training.batch_size, shuffle=True)\n",
        "    val_data = TextDataset(cfg.dataset.file_valid, cfg.model.context_length, Encoder(cfg.dataset.vocab))\n",
        "    val_loader = DataLoader(val_data, batch_size=cfg.training.batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model parameter\n",
        "    model.reset_parameters()\n",
        "    cfg.model.num_parameters = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    # Configure optimzier\n",
        "    optim_groups = model._create_weight_decay_optim_groups()\n",
        "    optimizer = optim.AdamW(\n",
        "        (\n",
        "            {\"weight_decay\": cfg.training.weight_decay, \"params\": optim_groups[0]},\n",
        "            {\"weight_decay\": 0.0, \"params\": optim_groups[1]},\n",
        "        ),\n",
        "        lr=cfg.training.lr\n",
        "    )\n",
        "\n",
        "    # Configure learning rate scheduler\n",
        "    warmup_scheduler = LambdaLR(\n",
        "        optimizer,\n",
        "        lr_lambda=lambda step: step / cfg.training.lr_warmup_steps\n",
        "    )\n",
        "    cosine_scheduler = CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max = cfg.training.lr_decay_until_steps-cfg.training.lr_warmup_steps,\n",
        "        eta_min = cfg.training.lr_min\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    step = 0\n",
        "    epoch = 1\n",
        "    running_loss = 0.0\n",
        "    accuracy = VocabularyAccuracy(cfg.model.vocab_size).to(device=cfg.training.device)\n",
        "    t0 = time.time()\n",
        "    while step < cfg.training.num_steps:\n",
        "        for sequence in train_loader:\n",
        "            inputs = sequence[:, :-1].to(device=cfg.training.device)\n",
        "            labels = sequence[:, 1:].to(device=cfg.training.device)\n",
        "\n",
        "            # Training step for (mini-)batches\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = F.cross_entropy(outputs.reshape((-1, outputs.shape[-1])),\n",
        "                                   labels.flatten())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr = optimizer.param_groups[0][\"lr\"]\n",
        "            if step < cfg.training.lr_warmup_steps:\n",
        "                warmup_scheduler.step()\n",
        "            else:\n",
        "                cosine_scheduler.step()\n",
        "            running_loss = running_loss * step / (step+1) + loss.item() * 1 / (step+1)\n",
        "\n",
        "            # Validation\n",
        "            if step % cfg.training.val_every_step == 0:\n",
        "                model.eval()\n",
        "                val_loss = 0.0\n",
        "                accuracy.reset()\n",
        "                with torch.no_grad():\n",
        "                    for val_sequence in val_loader:\n",
        "                        val_inputs = val_sequence[:, :-1].to(device=cfg.training.device)\n",
        "                        val_labels = val_sequence[:, 1:].to(device=cfg.training.device)\n",
        "                        val_outputs = model(val_inputs)\n",
        "                        loss = F.cross_entropy(val_outputs.reshape((-1, val_outputs.shape[-1])),\n",
        "                                               val_labels.flatten())\n",
        "                        val_loss += loss.item()\n",
        "                        accuracy.update(val_outputs, val_labels)\n",
        "                    val_loss /= len(val_loader)\n",
        "                    val_acc = accuracy.compute()\n",
        "\n",
        "                print(\n",
        "                    f\"Step {step:04d}/{cfg.training.num_steps} (Epoch: {epoch}), \"\n",
        "                    f\"Train loss: {running_loss:.4f}, Val loss: {val_loss:.4f}, Acc: {val_acc:.4f}, \"\n",
        "                    f\"LR: {lr:.2e}\"\n",
        "                )\n",
        "                logger.log(step, lr, running_loss, val_loss, val_acc)\n",
        "\n",
        "            step += 1\n",
        "            if step >= cfg.training.num_steps:\n",
        "                break\n",
        "        epoch += 1\n",
        "\n",
        "    print(f\"Completed in {time.time() - t0:.2f} seconds.\\n\")\n",
        "    return logger"
      ],
      "metadata": {
        "id": "KxbuTo7-wUbk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SPECIFICATION/HYPERPARAMETER SEARCH\n",
        "\n",
        "# Prepare lists of different specification/hyperparameter choices\n",
        "xlstm_models = [[], [0, 1], [1]]\n",
        "xlstm_model_names = [\"xLSTM[1:0]\", \"xLSTM[0:1]\", \"xLSTM[1:1]\"]\n",
        "learning_rates = [0.01, 0.001]\n",
        "num_heads = [[4, 4], [8, 8]]\n",
        "convolutions = [[1, 0], [4, 4]]\n",
        "embedding_dims = [64, 128]\n",
        "qkc_blocksizes = [4, 8]\n",
        "\n",
        "# Name of database\n",
        "database_name = cfg.database.name\n",
        "\n",
        "# 1 - Experiment with different learning rates\n",
        "experiment_name = \"learning_rate\"\n",
        "cfg_search = cfg.copy()\n",
        "n = 1\n",
        "for i, mdl in enumerate(xlstm_models):\n",
        "    for lr in learning_rates:\n",
        "        cfg_search.slstm_at = mdl\n",
        "        cfg_search.training.lr = lr\n",
        "        cfg_search.model.name = xlstm_model_names[i]\n",
        "        experiment_id = f\"{xlstm_model_names[i]}_{experiment_name}_{str(n)}\"\n",
        "        print(f\"Running experiment: {xlstm_model_names[i]}, Learning rate = {lr}\")\n",
        "        # Instantiate model, logger and database\n",
        "        model = xLSTMLMModel(from_dict(xLSTMLMModelConfig,\n",
        "                                      OmegaConf.to_container(cfg_search.model))).to(device=cfg_search.training.device)\n",
        "        logger = ExperimentLogger()\n",
        "        db = ExperimentDatabase(db_name=database_name)\n",
        "        # Run model\n",
        "        logger = main(cfg_search, model, logger)\n",
        "        # Add results to database\n",
        "        db.insert_experiment(cfg_search, logger.to_dataframe(), experiment_id=experiment_id)\n",
        "        n += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuiMV2OET5Fq",
        "outputId": "c72a9154-017e-4f16-a6aa-f70e0e215dfc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running experiment: xLSTM[1:0], Learning rate = 0.01\n",
            "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/usr/local/cuda/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:546: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, training, *inputs):\n",
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:571: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_s):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0000/1500 (Epoch: 1), Train loss: 3.8164, Val loss: 3.8038, Acc: 0.0287, LR: 0.00e+00\n",
            "Step 0030/1500 (Epoch: 1), Train loss: 2.6671, Val loss: 2.1157, Acc: 0.2046, LR: 3.00e-03\n",
            "Step 0060/1500 (Epoch: 2), Train loss: 2.2192, Val loss: 1.7295, Acc: 0.2955, LR: 6.00e-03\n",
            "Step 0090/1500 (Epoch: 2), Train loss: 1.9782, Val loss: 1.5443, Acc: 0.3537, LR: 9.00e-03\n",
            "Step 0120/1500 (Epoch: 3), Train loss: 1.8244, Val loss: 1.4696, Acc: 0.3933, LR: 9.99e-03\n",
            "Step 0150/1500 (Epoch: 3), Train loss: 1.7177, Val loss: 1.3949, Acc: 0.4230, LR: 9.97e-03\n",
            "Step 0180/1500 (Epoch: 4), Train loss: 1.6390, Val loss: 1.3604, Acc: 0.4458, LR: 9.92e-03\n",
            "Step 0210/1500 (Epoch: 5), Train loss: 1.5769, Val loss: 1.3590, Acc: 0.4626, LR: 9.85e-03\n",
            "Step 0240/1500 (Epoch: 5), Train loss: 1.5272, Val loss: 1.3276, Acc: 0.4770, LR: 9.76e-03\n",
            "Step 0270/1500 (Epoch: 6), Train loss: 1.4870, Val loss: 1.3109, Acc: 0.4887, LR: 9.64e-03\n",
            "Step 0300/1500 (Epoch: 6), Train loss: 1.4532, Val loss: 1.3126, Acc: 0.4981, LR: 9.51e-03\n",
            "Step 0330/1500 (Epoch: 7), Train loss: 1.4242, Val loss: 1.3007, Acc: 0.5065, LR: 9.35e-03\n",
            "Step 0360/1500 (Epoch: 7), Train loss: 1.3990, Val loss: 1.2806, Acc: 0.5138, LR: 9.17e-03\n",
            "Step 0390/1500 (Epoch: 8), Train loss: 1.3765, Val loss: 1.2800, Acc: 0.5204, LR: 8.98e-03\n",
            "Step 0420/1500 (Epoch: 9), Train loss: 1.3570, Val loss: 1.2832, Acc: 0.5260, LR: 8.77e-03\n",
            "Step 0450/1500 (Epoch: 9), Train loss: 1.3392, Val loss: 1.2586, Acc: 0.5312, LR: 8.54e-03\n",
            "Step 0480/1500 (Epoch: 10), Train loss: 1.3232, Val loss: 1.2559, Acc: 0.5360, LR: 8.29e-03\n",
            "Step 0510/1500 (Epoch: 10), Train loss: 1.3088, Val loss: 1.2520, Acc: 0.5401, LR: 8.03e-03\n",
            "Step 0540/1500 (Epoch: 11), Train loss: 1.2950, Val loss: 1.2533, Acc: 0.5437, LR: 7.76e-03\n",
            "Step 0570/1500 (Epoch: 11), Train loss: 1.2829, Val loss: 1.2324, Acc: 0.5475, LR: 7.47e-03\n",
            "Step 0600/1500 (Epoch: 12), Train loss: 1.2709, Val loss: 1.2437, Acc: 0.5505, LR: 7.17e-03\n",
            "Step 0630/1500 (Epoch: 13), Train loss: 1.2603, Val loss: 1.2508, Acc: 0.5534, LR: 6.86e-03\n",
            "Step 0660/1500 (Epoch: 13), Train loss: 1.2503, Val loss: 1.2277, Acc: 0.5563, LR: 6.55e-03\n",
            "Step 0690/1500 (Epoch: 14), Train loss: 1.2406, Val loss: 1.2338, Acc: 0.5589, LR: 6.23e-03\n",
            "Step 0720/1500 (Epoch: 14), Train loss: 1.2318, Val loss: 1.2295, Acc: 0.5613, LR: 5.90e-03\n",
            "Step 0750/1500 (Epoch: 15), Train loss: 1.2231, Val loss: 1.2245, Acc: 0.5635, LR: 5.56e-03\n",
            "Step 0780/1500 (Epoch: 16), Train loss: 1.2151, Val loss: 1.2229, Acc: 0.5656, LR: 5.23e-03\n",
            "Step 0810/1500 (Epoch: 16), Train loss: 1.2071, Val loss: 1.2210, Acc: 0.5675, LR: 4.89e-03\n",
            "Step 0840/1500 (Epoch: 17), Train loss: 1.1997, Val loss: 1.2138, Acc: 0.5694, LR: 4.56e-03\n",
            "Step 0870/1500 (Epoch: 17), Train loss: 1.1925, Val loss: 1.2197, Acc: 0.5711, LR: 4.22e-03\n",
            "Step 0900/1500 (Epoch: 18), Train loss: 1.1854, Val loss: 1.2209, Acc: 0.5728, LR: 3.89e-03\n",
            "Step 0930/1500 (Epoch: 18), Train loss: 1.1788, Val loss: 1.1986, Acc: 0.5744, LR: 3.57e-03\n",
            "Step 0960/1500 (Epoch: 19), Train loss: 1.1722, Val loss: 1.2039, Acc: 0.5759, LR: 3.25e-03\n",
            "Step 0990/1500 (Epoch: 20), Train loss: 1.1660, Val loss: 1.2125, Acc: 0.5774, LR: 2.94e-03\n",
            "Step 1020/1500 (Epoch: 20), Train loss: 1.1597, Val loss: 1.2091, Acc: 0.5788, LR: 2.64e-03\n",
            "Step 1050/1500 (Epoch: 21), Train loss: 1.1537, Val loss: 1.2054, Acc: 0.5802, LR: 2.35e-03\n",
            "Step 1080/1500 (Epoch: 21), Train loss: 1.1478, Val loss: 1.1981, Acc: 0.5816, LR: 2.07e-03\n",
            "Step 1110/1500 (Epoch: 22), Train loss: 1.1420, Val loss: 1.2011, Acc: 0.5829, LR: 1.80e-03\n",
            "Step 1140/1500 (Epoch: 22), Train loss: 1.1365, Val loss: 1.1968, Acc: 0.5841, LR: 1.55e-03\n",
            "Step 1170/1500 (Epoch: 23), Train loss: 1.1309, Val loss: 1.1985, Acc: 0.5854, LR: 1.32e-03\n",
            "Step 1200/1500 (Epoch: 24), Train loss: 1.1256, Val loss: 1.1969, Acc: 0.5865, LR: 1.10e-03\n",
            "Step 1230/1500 (Epoch: 24), Train loss: 1.1203, Val loss: 1.1933, Acc: 0.5877, LR: 8.99e-04\n",
            "Step 1260/1500 (Epoch: 25), Train loss: 1.1152, Val loss: 1.2019, Acc: 0.5887, LR: 7.17e-04\n",
            "Step 1290/1500 (Epoch: 25), Train loss: 1.1101, Val loss: 1.1948, Acc: 0.5897, LR: 5.54e-04\n",
            "Step 1320/1500 (Epoch: 26), Train loss: 1.1052, Val loss: 1.2008, Acc: 0.5907, LR: 4.12e-04\n",
            "Step 1350/1500 (Epoch: 26), Train loss: 1.1005, Val loss: 1.1948, Acc: 0.5917, LR: 2.90e-04\n",
            "Step 1380/1500 (Epoch: 27), Train loss: 1.0958, Val loss: 1.1984, Acc: 0.5926, LR: 1.90e-04\n",
            "Step 1410/1500 (Epoch: 28), Train loss: 1.0913, Val loss: 1.1985, Acc: 0.5935, LR: 1.12e-04\n",
            "Step 1440/1500 (Epoch: 28), Train loss: 1.0869, Val loss: 1.1984, Acc: 0.5943, LR: 5.52e-05\n",
            "Step 1470/1500 (Epoch: 29), Train loss: 1.0827, Val loss: 1.1985, Acc: 0.5951, LR: 2.13e-05\n",
            "Completed in 60.05 seconds.\n",
            "\n",
            "Running experiment: xLSTM[1:0], Learning rate = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:546: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, training, *inputs):\n",
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:571: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_s):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0000/1500 (Epoch: 1), Train loss: 3.8594, Val loss: 3.8771, Acc: 0.0272, LR: 0.00e+00\n",
            "Step 0030/1500 (Epoch: 1), Train loss: 3.3388, Val loss: 2.7420, Acc: 0.1484, LR: 3.00e-04\n",
            "Step 0060/1500 (Epoch: 2), Train loss: 2.8657, Val loss: 2.2347, Acc: 0.2189, LR: 6.00e-04\n",
            "Step 0090/1500 (Epoch: 2), Train loss: 2.5680, Val loss: 1.9479, Acc: 0.2703, LR: 9.00e-04\n",
            "Step 0120/1500 (Epoch: 3), Train loss: 2.3555, Val loss: 1.7879, Acc: 0.3101, LR: 1.00e-03\n",
            "Step 0150/1500 (Epoch: 3), Train loss: 2.2010, Val loss: 1.6675, Acc: 0.3424, LR: 9.97e-04\n",
            "Step 0180/1500 (Epoch: 4), Train loss: 2.0839, Val loss: 1.5992, Acc: 0.3674, LR: 9.92e-04\n",
            "Step 0210/1500 (Epoch: 5), Train loss: 1.9905, Val loss: 1.5500, Acc: 0.3883, LR: 9.85e-04\n",
            "Step 0240/1500 (Epoch: 5), Train loss: 1.9146, Val loss: 1.5025, Acc: 0.4057, LR: 9.76e-04\n",
            "Step 0270/1500 (Epoch: 6), Train loss: 1.8519, Val loss: 1.4763, Acc: 0.4202, LR: 9.64e-04\n",
            "Step 0300/1500 (Epoch: 6), Train loss: 1.7988, Val loss: 1.4481, Acc: 0.4328, LR: 9.51e-04\n",
            "Step 0330/1500 (Epoch: 7), Train loss: 1.7531, Val loss: 1.4291, Acc: 0.4437, LR: 9.36e-04\n",
            "Step 0360/1500 (Epoch: 7), Train loss: 1.7128, Val loss: 1.4119, Acc: 0.4532, LR: 9.18e-04\n",
            "Step 0390/1500 (Epoch: 8), Train loss: 1.6773, Val loss: 1.3943, Acc: 0.4619, LR: 8.99e-04\n",
            "Step 0420/1500 (Epoch: 9), Train loss: 1.6458, Val loss: 1.3927, Acc: 0.4695, LR: 8.78e-04\n",
            "Step 0450/1500 (Epoch: 9), Train loss: 1.6176, Val loss: 1.3689, Acc: 0.4764, LR: 8.55e-04\n",
            "Step 0480/1500 (Epoch: 10), Train loss: 1.5919, Val loss: 1.3591, Acc: 0.4824, LR: 8.31e-04\n",
            "Step 0510/1500 (Epoch: 10), Train loss: 1.5689, Val loss: 1.3523, Acc: 0.4883, LR: 8.05e-04\n",
            "Step 0540/1500 (Epoch: 11), Train loss: 1.5474, Val loss: 1.3473, Acc: 0.4935, LR: 7.78e-04\n",
            "Step 0570/1500 (Epoch: 11), Train loss: 1.5280, Val loss: 1.3311, Acc: 0.4984, LR: 7.49e-04\n",
            "Step 0600/1500 (Epoch: 12), Train loss: 1.5097, Val loss: 1.3262, Acc: 0.5029, LR: 7.20e-04\n",
            "Step 0630/1500 (Epoch: 13), Train loss: 1.4931, Val loss: 1.3234, Acc: 0.5071, LR: 6.89e-04\n",
            "Step 0660/1500 (Epoch: 13), Train loss: 1.4777, Val loss: 1.3157, Acc: 0.5108, LR: 6.58e-04\n",
            "Step 0690/1500 (Epoch: 14), Train loss: 1.4631, Val loss: 1.3157, Acc: 0.5143, LR: 6.26e-04\n",
            "Step 0720/1500 (Epoch: 14), Train loss: 1.4497, Val loss: 1.3057, Acc: 0.5177, LR: 5.93e-04\n",
            "Step 0750/1500 (Epoch: 15), Train loss: 1.4369, Val loss: 1.3058, Acc: 0.5208, LR: 5.60e-04\n",
            "Step 0780/1500 (Epoch: 16), Train loss: 1.4250, Val loss: 1.3012, Acc: 0.5237, LR: 5.27e-04\n",
            "Step 0810/1500 (Epoch: 16), Train loss: 1.4136, Val loss: 1.2954, Acc: 0.5265, LR: 4.94e-04\n",
            "Step 0840/1500 (Epoch: 17), Train loss: 1.4031, Val loss: 1.2954, Acc: 0.5291, LR: 4.61e-04\n",
            "Step 0870/1500 (Epoch: 17), Train loss: 1.3930, Val loss: 1.2857, Acc: 0.5316, LR: 4.28e-04\n",
            "Step 0900/1500 (Epoch: 18), Train loss: 1.3834, Val loss: 1.2875, Acc: 0.5338, LR: 3.95e-04\n",
            "Step 0930/1500 (Epoch: 18), Train loss: 1.3745, Val loss: 1.2821, Acc: 0.5361, LR: 3.63e-04\n",
            "Step 0960/1500 (Epoch: 19), Train loss: 1.3659, Val loss: 1.2839, Acc: 0.5382, LR: 3.31e-04\n",
            "Step 0990/1500 (Epoch: 20), Train loss: 1.3577, Val loss: 1.2795, Acc: 0.5402, LR: 3.00e-04\n",
            "Step 1020/1500 (Epoch: 20), Train loss: 1.3499, Val loss: 1.2788, Acc: 0.5421, LR: 2.70e-04\n",
            "Step 1050/1500 (Epoch: 21), Train loss: 1.3423, Val loss: 1.2733, Acc: 0.5438, LR: 2.42e-04\n",
            "Step 1080/1500 (Epoch: 21), Train loss: 1.3352, Val loss: 1.2734, Acc: 0.5455, LR: 2.14e-04\n",
            "Step 1110/1500 (Epoch: 22), Train loss: 1.3285, Val loss: 1.2719, Acc: 0.5471, LR: 1.88e-04\n",
            "Step 1140/1500 (Epoch: 22), Train loss: 1.3220, Val loss: 1.2698, Acc: 0.5487, LR: 1.63e-04\n",
            "Step 1170/1500 (Epoch: 23), Train loss: 1.3158, Val loss: 1.2680, Acc: 0.5502, LR: 1.40e-04\n",
            "Step 1200/1500 (Epoch: 24), Train loss: 1.3098, Val loss: 1.2688, Acc: 0.5516, LR: 1.18e-04\n",
            "Step 1230/1500 (Epoch: 24), Train loss: 1.3041, Val loss: 1.2656, Acc: 0.5530, LR: 9.81e-05\n",
            "Step 1260/1500 (Epoch: 25), Train loss: 1.2986, Val loss: 1.2674, Acc: 0.5543, LR: 8.01e-05\n",
            "Step 1290/1500 (Epoch: 25), Train loss: 1.2933, Val loss: 1.2650, Acc: 0.5555, LR: 6.40e-05\n",
            "Step 1320/1500 (Epoch: 26), Train loss: 1.2883, Val loss: 1.2655, Acc: 0.5567, LR: 4.98e-05\n",
            "Step 1350/1500 (Epoch: 26), Train loss: 1.2834, Val loss: 1.2641, Acc: 0.5579, LR: 3.78e-05\n",
            "Step 1380/1500 (Epoch: 27), Train loss: 1.2788, Val loss: 1.2632, Acc: 0.5589, LR: 2.78e-05\n",
            "Step 1410/1500 (Epoch: 28), Train loss: 1.2743, Val loss: 1.2633, Acc: 0.5600, LR: 2.01e-05\n",
            "Step 1440/1500 (Epoch: 28), Train loss: 1.2700, Val loss: 1.2632, Acc: 0.5610, LR: 1.45e-05\n",
            "Step 1470/1500 (Epoch: 29), Train loss: 1.2659, Val loss: 1.2631, Acc: 0.5620, LR: 1.11e-05\n",
            "Completed in 58.83 seconds.\n",
            "\n",
            "Running experiment: xLSTM[0:1], Learning rate = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:546: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, training, *inputs):\n",
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:571: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_s):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0000/1500 (Epoch: 1), Train loss: 3.8594, Val loss: 3.8771, Acc: 0.0272, LR: 0.00e+00\n",
            "Step 0030/1500 (Epoch: 1), Train loss: 2.6649, Val loss: 2.1015, Acc: 0.2050, LR: 3.00e-03\n",
            "Step 0060/1500 (Epoch: 2), Train loss: 2.2122, Val loss: 1.7166, Acc: 0.2981, LR: 6.00e-03\n",
            "Step 0090/1500 (Epoch: 2), Train loss: 1.9719, Val loss: 1.5489, Acc: 0.3555, LR: 9.00e-03\n",
            "Step 0120/1500 (Epoch: 3), Train loss: 1.8189, Val loss: 1.4490, Acc: 0.3960, LR: 9.99e-03\n",
            "Step 0150/1500 (Epoch: 3), Train loss: 1.7126, Val loss: 1.3962, Acc: 0.4250, LR: 9.97e-03\n",
            "Step 0180/1500 (Epoch: 4), Train loss: 1.6340, Val loss: 1.3632, Acc: 0.4472, LR: 9.92e-03\n",
            "Step 0210/1500 (Epoch: 5), Train loss: 1.5724, Val loss: 1.3481, Acc: 0.4646, LR: 9.85e-03\n",
            "Step 0240/1500 (Epoch: 5), Train loss: 1.5229, Val loss: 1.3247, Acc: 0.4787, LR: 9.76e-03\n",
            "Step 0270/1500 (Epoch: 6), Train loss: 1.4827, Val loss: 1.3067, Acc: 0.4904, LR: 9.64e-03\n",
            "Step 0300/1500 (Epoch: 6), Train loss: 1.4490, Val loss: 1.3029, Acc: 0.4999, LR: 9.51e-03\n",
            "Step 0330/1500 (Epoch: 7), Train loss: 1.4201, Val loss: 1.3002, Acc: 0.5081, LR: 9.35e-03\n",
            "Step 0360/1500 (Epoch: 7), Train loss: 1.3950, Val loss: 1.2783, Acc: 0.5153, LR: 9.17e-03\n",
            "Step 0390/1500 (Epoch: 8), Train loss: 1.3726, Val loss: 1.2711, Acc: 0.5216, LR: 8.98e-03\n",
            "Step 0420/1500 (Epoch: 9), Train loss: 1.3532, Val loss: 1.2828, Acc: 0.5269, LR: 8.77e-03\n",
            "Step 0450/1500 (Epoch: 9), Train loss: 1.3354, Val loss: 1.2534, Acc: 0.5320, LR: 8.54e-03\n",
            "Step 0480/1500 (Epoch: 10), Train loss: 1.3194, Val loss: 1.2553, Acc: 0.5367, LR: 8.29e-03\n",
            "Step 0510/1500 (Epoch: 10), Train loss: 1.3051, Val loss: 1.2435, Acc: 0.5409, LR: 8.03e-03\n",
            "Step 0540/1500 (Epoch: 11), Train loss: 1.2913, Val loss: 1.2597, Acc: 0.5445, LR: 7.76e-03\n",
            "Step 0570/1500 (Epoch: 11), Train loss: 1.2792, Val loss: 1.2305, Acc: 0.5482, LR: 7.47e-03\n",
            "Step 0600/1500 (Epoch: 12), Train loss: 1.2672, Val loss: 1.2409, Acc: 0.5513, LR: 7.17e-03\n",
            "Step 0630/1500 (Epoch: 13), Train loss: 1.2566, Val loss: 1.2470, Acc: 0.5541, LR: 6.86e-03\n",
            "Step 0660/1500 (Epoch: 13), Train loss: 1.2466, Val loss: 1.2298, Acc: 0.5568, LR: 6.55e-03\n",
            "Step 0690/1500 (Epoch: 14), Train loss: 1.2370, Val loss: 1.2359, Acc: 0.5593, LR: 6.23e-03\n",
            "Step 0720/1500 (Epoch: 14), Train loss: 1.2282, Val loss: 1.2200, Acc: 0.5617, LR: 5.90e-03\n",
            "Step 0750/1500 (Epoch: 15), Train loss: 1.2194, Val loss: 1.2221, Acc: 0.5640, LR: 5.56e-03\n",
            "Step 0780/1500 (Epoch: 16), Train loss: 1.2115, Val loss: 1.2152, Acc: 0.5661, LR: 5.23e-03\n",
            "Step 0810/1500 (Epoch: 16), Train loss: 1.2034, Val loss: 1.2151, Acc: 0.5681, LR: 4.89e-03\n",
            "Step 0840/1500 (Epoch: 17), Train loss: 1.1961, Val loss: 1.2119, Acc: 0.5701, LR: 4.56e-03\n",
            "Step 0870/1500 (Epoch: 17), Train loss: 1.1889, Val loss: 1.2080, Acc: 0.5719, LR: 4.22e-03\n",
            "Step 0900/1500 (Epoch: 18), Train loss: 1.1818, Val loss: 1.2083, Acc: 0.5737, LR: 3.89e-03\n",
            "Step 0930/1500 (Epoch: 18), Train loss: 1.1753, Val loss: 1.1939, Acc: 0.5754, LR: 3.57e-03\n",
            "Step 0960/1500 (Epoch: 19), Train loss: 1.1687, Val loss: 1.2055, Acc: 0.5770, LR: 3.25e-03\n",
            "Step 0990/1500 (Epoch: 20), Train loss: 1.1625, Val loss: 1.2106, Acc: 0.5785, LR: 2.94e-03\n",
            "Step 1020/1500 (Epoch: 20), Train loss: 1.1562, Val loss: 1.2027, Acc: 0.5799, LR: 2.64e-03\n",
            "Step 1050/1500 (Epoch: 21), Train loss: 1.1502, Val loss: 1.2051, Acc: 0.5813, LR: 2.35e-03\n",
            "Step 1080/1500 (Epoch: 21), Train loss: 1.1443, Val loss: 1.1929, Acc: 0.5826, LR: 2.07e-03\n",
            "Step 1110/1500 (Epoch: 22), Train loss: 1.1386, Val loss: 1.2011, Acc: 0.5839, LR: 1.80e-03\n",
            "Step 1140/1500 (Epoch: 22), Train loss: 1.1331, Val loss: 1.1937, Acc: 0.5852, LR: 1.55e-03\n",
            "Step 1170/1500 (Epoch: 23), Train loss: 1.1275, Val loss: 1.1956, Acc: 0.5863, LR: 1.32e-03\n",
            "Step 1200/1500 (Epoch: 24), Train loss: 1.1222, Val loss: 1.1970, Acc: 0.5874, LR: 1.10e-03\n",
            "Step 1230/1500 (Epoch: 24), Train loss: 1.1169, Val loss: 1.1943, Acc: 0.5886, LR: 8.99e-04\n",
            "Step 1260/1500 (Epoch: 25), Train loss: 1.1118, Val loss: 1.1987, Acc: 0.5896, LR: 7.17e-04\n",
            "Step 1290/1500 (Epoch: 25), Train loss: 1.1068, Val loss: 1.1944, Acc: 0.5906, LR: 5.54e-04\n",
            "Step 1320/1500 (Epoch: 26), Train loss: 1.1019, Val loss: 1.1963, Acc: 0.5916, LR: 4.12e-04\n",
            "Step 1350/1500 (Epoch: 26), Train loss: 1.0972, Val loss: 1.1936, Acc: 0.5925, LR: 2.90e-04\n",
            "Step 1380/1500 (Epoch: 27), Train loss: 1.0925, Val loss: 1.1983, Acc: 0.5934, LR: 1.90e-04\n",
            "Step 1410/1500 (Epoch: 28), Train loss: 1.0880, Val loss: 1.1964, Acc: 0.5943, LR: 1.12e-04\n",
            "Step 1440/1500 (Epoch: 28), Train loss: 1.0836, Val loss: 1.1971, Acc: 0.5951, LR: 5.52e-05\n",
            "Step 1470/1500 (Epoch: 29), Train loss: 1.0794, Val loss: 1.1968, Acc: 0.5959, LR: 2.13e-05\n",
            "Completed in 58.92 seconds.\n",
            "\n",
            "Running experiment: xLSTM[0:1], Learning rate = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:546: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, training, *inputs):\n",
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:571: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_s):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0000/1500 (Epoch: 1), Train loss: 3.8594, Val loss: 3.8771, Acc: 0.0272, LR: 0.00e+00\n",
            "Step 0030/1500 (Epoch: 1), Train loss: 3.3388, Val loss: 2.7420, Acc: 0.1484, LR: 3.00e-04\n",
            "Step 0060/1500 (Epoch: 2), Train loss: 2.8657, Val loss: 2.2347, Acc: 0.2189, LR: 6.00e-04\n",
            "Step 0090/1500 (Epoch: 2), Train loss: 2.5680, Val loss: 1.9479, Acc: 0.2703, LR: 9.00e-04\n",
            "Step 0120/1500 (Epoch: 3), Train loss: 2.3555, Val loss: 1.7879, Acc: 0.3101, LR: 1.00e-03\n",
            "Step 0150/1500 (Epoch: 3), Train loss: 2.2010, Val loss: 1.6675, Acc: 0.3424, LR: 9.97e-04\n",
            "Step 0180/1500 (Epoch: 4), Train loss: 2.0839, Val loss: 1.5992, Acc: 0.3674, LR: 9.92e-04\n",
            "Step 0210/1500 (Epoch: 5), Train loss: 1.9905, Val loss: 1.5500, Acc: 0.3883, LR: 9.85e-04\n",
            "Step 0240/1500 (Epoch: 5), Train loss: 1.9146, Val loss: 1.5025, Acc: 0.4057, LR: 9.76e-04\n",
            "Step 0270/1500 (Epoch: 6), Train loss: 1.8519, Val loss: 1.4763, Acc: 0.4202, LR: 9.64e-04\n",
            "Step 0300/1500 (Epoch: 6), Train loss: 1.7988, Val loss: 1.4481, Acc: 0.4328, LR: 9.51e-04\n",
            "Step 0330/1500 (Epoch: 7), Train loss: 1.7531, Val loss: 1.4291, Acc: 0.4437, LR: 9.36e-04\n",
            "Step 0360/1500 (Epoch: 7), Train loss: 1.7128, Val loss: 1.4119, Acc: 0.4532, LR: 9.18e-04\n",
            "Step 0390/1500 (Epoch: 8), Train loss: 1.6773, Val loss: 1.3943, Acc: 0.4619, LR: 8.99e-04\n",
            "Step 0420/1500 (Epoch: 9), Train loss: 1.6458, Val loss: 1.3927, Acc: 0.4695, LR: 8.78e-04\n",
            "Step 0450/1500 (Epoch: 9), Train loss: 1.6176, Val loss: 1.3689, Acc: 0.4764, LR: 8.55e-04\n",
            "Step 0480/1500 (Epoch: 10), Train loss: 1.5919, Val loss: 1.3591, Acc: 0.4824, LR: 8.31e-04\n",
            "Step 0510/1500 (Epoch: 10), Train loss: 1.5689, Val loss: 1.3523, Acc: 0.4883, LR: 8.05e-04\n",
            "Step 0540/1500 (Epoch: 11), Train loss: 1.5474, Val loss: 1.3473, Acc: 0.4935, LR: 7.78e-04\n",
            "Step 0570/1500 (Epoch: 11), Train loss: 1.5280, Val loss: 1.3311, Acc: 0.4984, LR: 7.49e-04\n",
            "Step 0600/1500 (Epoch: 12), Train loss: 1.5097, Val loss: 1.3262, Acc: 0.5029, LR: 7.20e-04\n",
            "Step 0630/1500 (Epoch: 13), Train loss: 1.4931, Val loss: 1.3234, Acc: 0.5071, LR: 6.89e-04\n",
            "Step 0660/1500 (Epoch: 13), Train loss: 1.4777, Val loss: 1.3157, Acc: 0.5108, LR: 6.58e-04\n",
            "Step 0690/1500 (Epoch: 14), Train loss: 1.4631, Val loss: 1.3157, Acc: 0.5143, LR: 6.26e-04\n",
            "Step 0720/1500 (Epoch: 14), Train loss: 1.4497, Val loss: 1.3057, Acc: 0.5177, LR: 5.93e-04\n",
            "Step 0750/1500 (Epoch: 15), Train loss: 1.4369, Val loss: 1.3058, Acc: 0.5208, LR: 5.60e-04\n",
            "Step 0780/1500 (Epoch: 16), Train loss: 1.4250, Val loss: 1.3012, Acc: 0.5237, LR: 5.27e-04\n",
            "Step 0810/1500 (Epoch: 16), Train loss: 1.4136, Val loss: 1.2954, Acc: 0.5265, LR: 4.94e-04\n",
            "Step 0840/1500 (Epoch: 17), Train loss: 1.4031, Val loss: 1.2954, Acc: 0.5291, LR: 4.61e-04\n",
            "Step 0870/1500 (Epoch: 17), Train loss: 1.3930, Val loss: 1.2857, Acc: 0.5316, LR: 4.28e-04\n",
            "Step 0900/1500 (Epoch: 18), Train loss: 1.3834, Val loss: 1.2875, Acc: 0.5338, LR: 3.95e-04\n",
            "Step 0930/1500 (Epoch: 18), Train loss: 1.3745, Val loss: 1.2821, Acc: 0.5361, LR: 3.63e-04\n",
            "Step 0960/1500 (Epoch: 19), Train loss: 1.3659, Val loss: 1.2839, Acc: 0.5382, LR: 3.31e-04\n",
            "Step 0990/1500 (Epoch: 20), Train loss: 1.3577, Val loss: 1.2795, Acc: 0.5402, LR: 3.00e-04\n",
            "Step 1020/1500 (Epoch: 20), Train loss: 1.3499, Val loss: 1.2788, Acc: 0.5421, LR: 2.70e-04\n",
            "Step 1050/1500 (Epoch: 21), Train loss: 1.3423, Val loss: 1.2733, Acc: 0.5438, LR: 2.42e-04\n",
            "Step 1080/1500 (Epoch: 21), Train loss: 1.3352, Val loss: 1.2734, Acc: 0.5455, LR: 2.14e-04\n",
            "Step 1110/1500 (Epoch: 22), Train loss: 1.3285, Val loss: 1.2719, Acc: 0.5471, LR: 1.88e-04\n",
            "Step 1140/1500 (Epoch: 22), Train loss: 1.3220, Val loss: 1.2698, Acc: 0.5487, LR: 1.63e-04\n",
            "Step 1170/1500 (Epoch: 23), Train loss: 1.3158, Val loss: 1.2680, Acc: 0.5502, LR: 1.40e-04\n",
            "Step 1200/1500 (Epoch: 24), Train loss: 1.3098, Val loss: 1.2688, Acc: 0.5516, LR: 1.18e-04\n",
            "Step 1230/1500 (Epoch: 24), Train loss: 1.3041, Val loss: 1.2656, Acc: 0.5530, LR: 9.81e-05\n",
            "Step 1260/1500 (Epoch: 25), Train loss: 1.2986, Val loss: 1.2674, Acc: 0.5543, LR: 8.01e-05\n",
            "Step 1290/1500 (Epoch: 25), Train loss: 1.2933, Val loss: 1.2650, Acc: 0.5555, LR: 6.40e-05\n",
            "Step 1320/1500 (Epoch: 26), Train loss: 1.2883, Val loss: 1.2655, Acc: 0.5567, LR: 4.98e-05\n",
            "Step 1350/1500 (Epoch: 26), Train loss: 1.2834, Val loss: 1.2641, Acc: 0.5579, LR: 3.78e-05\n",
            "Step 1380/1500 (Epoch: 27), Train loss: 1.2788, Val loss: 1.2632, Acc: 0.5589, LR: 2.78e-05\n",
            "Step 1410/1500 (Epoch: 28), Train loss: 1.2743, Val loss: 1.2633, Acc: 0.5600, LR: 2.01e-05\n",
            "Step 1440/1500 (Epoch: 28), Train loss: 1.2700, Val loss: 1.2632, Acc: 0.5610, LR: 1.45e-05\n",
            "Step 1470/1500 (Epoch: 29), Train loss: 1.2659, Val loss: 1.2631, Acc: 0.5620, LR: 1.11e-05\n",
            "Completed in 58.80 seconds.\n",
            "\n",
            "Running experiment: xLSTM[1:1], Learning rate = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:546: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, training, *inputs):\n",
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:571: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_s):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0000/1500 (Epoch: 1), Train loss: 3.8594, Val loss: 3.8771, Acc: 0.0272, LR: 0.00e+00\n",
            "Step 0030/1500 (Epoch: 1), Train loss: 2.6649, Val loss: 2.1015, Acc: 0.2050, LR: 3.00e-03\n",
            "Step 0060/1500 (Epoch: 2), Train loss: 2.2122, Val loss: 1.7166, Acc: 0.2981, LR: 6.00e-03\n",
            "Step 0090/1500 (Epoch: 2), Train loss: 1.9719, Val loss: 1.5489, Acc: 0.3555, LR: 9.00e-03\n",
            "Step 0120/1500 (Epoch: 3), Train loss: 1.8189, Val loss: 1.4490, Acc: 0.3960, LR: 9.99e-03\n",
            "Step 0150/1500 (Epoch: 3), Train loss: 1.7126, Val loss: 1.3962, Acc: 0.4250, LR: 9.97e-03\n",
            "Step 0180/1500 (Epoch: 4), Train loss: 1.6340, Val loss: 1.3632, Acc: 0.4472, LR: 9.92e-03\n",
            "Step 0210/1500 (Epoch: 5), Train loss: 1.5724, Val loss: 1.3481, Acc: 0.4646, LR: 9.85e-03\n",
            "Step 0240/1500 (Epoch: 5), Train loss: 1.5229, Val loss: 1.3247, Acc: 0.4787, LR: 9.76e-03\n",
            "Step 0270/1500 (Epoch: 6), Train loss: 1.4827, Val loss: 1.3067, Acc: 0.4904, LR: 9.64e-03\n",
            "Step 0300/1500 (Epoch: 6), Train loss: 1.4490, Val loss: 1.3029, Acc: 0.4999, LR: 9.51e-03\n",
            "Step 0330/1500 (Epoch: 7), Train loss: 1.4201, Val loss: 1.3002, Acc: 0.5081, LR: 9.35e-03\n",
            "Step 0360/1500 (Epoch: 7), Train loss: 1.3950, Val loss: 1.2783, Acc: 0.5153, LR: 9.17e-03\n",
            "Step 0390/1500 (Epoch: 8), Train loss: 1.3726, Val loss: 1.2711, Acc: 0.5216, LR: 8.98e-03\n",
            "Step 0420/1500 (Epoch: 9), Train loss: 1.3532, Val loss: 1.2828, Acc: 0.5269, LR: 8.77e-03\n",
            "Step 0450/1500 (Epoch: 9), Train loss: 1.3354, Val loss: 1.2534, Acc: 0.5320, LR: 8.54e-03\n",
            "Step 0480/1500 (Epoch: 10), Train loss: 1.3194, Val loss: 1.2553, Acc: 0.5367, LR: 8.29e-03\n",
            "Step 0510/1500 (Epoch: 10), Train loss: 1.3051, Val loss: 1.2435, Acc: 0.5409, LR: 8.03e-03\n",
            "Step 0540/1500 (Epoch: 11), Train loss: 1.2913, Val loss: 1.2597, Acc: 0.5445, LR: 7.76e-03\n",
            "Step 0570/1500 (Epoch: 11), Train loss: 1.2792, Val loss: 1.2305, Acc: 0.5482, LR: 7.47e-03\n",
            "Step 0600/1500 (Epoch: 12), Train loss: 1.2672, Val loss: 1.2409, Acc: 0.5513, LR: 7.17e-03\n",
            "Step 0630/1500 (Epoch: 13), Train loss: 1.2566, Val loss: 1.2470, Acc: 0.5541, LR: 6.86e-03\n",
            "Step 0660/1500 (Epoch: 13), Train loss: 1.2466, Val loss: 1.2298, Acc: 0.5568, LR: 6.55e-03\n",
            "Step 0690/1500 (Epoch: 14), Train loss: 1.2370, Val loss: 1.2359, Acc: 0.5593, LR: 6.23e-03\n",
            "Step 0720/1500 (Epoch: 14), Train loss: 1.2282, Val loss: 1.2200, Acc: 0.5617, LR: 5.90e-03\n",
            "Step 0750/1500 (Epoch: 15), Train loss: 1.2194, Val loss: 1.2221, Acc: 0.5640, LR: 5.56e-03\n",
            "Step 0780/1500 (Epoch: 16), Train loss: 1.2115, Val loss: 1.2152, Acc: 0.5661, LR: 5.23e-03\n",
            "Step 0810/1500 (Epoch: 16), Train loss: 1.2034, Val loss: 1.2151, Acc: 0.5681, LR: 4.89e-03\n",
            "Step 0840/1500 (Epoch: 17), Train loss: 1.1961, Val loss: 1.2119, Acc: 0.5701, LR: 4.56e-03\n",
            "Step 0870/1500 (Epoch: 17), Train loss: 1.1889, Val loss: 1.2080, Acc: 0.5719, LR: 4.22e-03\n",
            "Step 0900/1500 (Epoch: 18), Train loss: 1.1818, Val loss: 1.2083, Acc: 0.5737, LR: 3.89e-03\n",
            "Step 0930/1500 (Epoch: 18), Train loss: 1.1753, Val loss: 1.1939, Acc: 0.5754, LR: 3.57e-03\n",
            "Step 0960/1500 (Epoch: 19), Train loss: 1.1687, Val loss: 1.2055, Acc: 0.5770, LR: 3.25e-03\n",
            "Step 0990/1500 (Epoch: 20), Train loss: 1.1625, Val loss: 1.2106, Acc: 0.5785, LR: 2.94e-03\n",
            "Step 1020/1500 (Epoch: 20), Train loss: 1.1562, Val loss: 1.2027, Acc: 0.5799, LR: 2.64e-03\n",
            "Step 1050/1500 (Epoch: 21), Train loss: 1.1502, Val loss: 1.2051, Acc: 0.5813, LR: 2.35e-03\n",
            "Step 1080/1500 (Epoch: 21), Train loss: 1.1443, Val loss: 1.1929, Acc: 0.5826, LR: 2.07e-03\n",
            "Step 1110/1500 (Epoch: 22), Train loss: 1.1386, Val loss: 1.2011, Acc: 0.5839, LR: 1.80e-03\n",
            "Step 1140/1500 (Epoch: 22), Train loss: 1.1331, Val loss: 1.1937, Acc: 0.5852, LR: 1.55e-03\n",
            "Step 1170/1500 (Epoch: 23), Train loss: 1.1275, Val loss: 1.1956, Acc: 0.5863, LR: 1.32e-03\n",
            "Step 1200/1500 (Epoch: 24), Train loss: 1.1222, Val loss: 1.1970, Acc: 0.5874, LR: 1.10e-03\n",
            "Step 1230/1500 (Epoch: 24), Train loss: 1.1169, Val loss: 1.1943, Acc: 0.5886, LR: 8.99e-04\n",
            "Step 1260/1500 (Epoch: 25), Train loss: 1.1118, Val loss: 1.1987, Acc: 0.5896, LR: 7.17e-04\n",
            "Step 1290/1500 (Epoch: 25), Train loss: 1.1068, Val loss: 1.1944, Acc: 0.5906, LR: 5.54e-04\n",
            "Step 1320/1500 (Epoch: 26), Train loss: 1.1019, Val loss: 1.1963, Acc: 0.5916, LR: 4.12e-04\n",
            "Step 1350/1500 (Epoch: 26), Train loss: 1.0972, Val loss: 1.1936, Acc: 0.5925, LR: 2.90e-04\n",
            "Step 1380/1500 (Epoch: 27), Train loss: 1.0925, Val loss: 1.1983, Acc: 0.5934, LR: 1.90e-04\n",
            "Step 1410/1500 (Epoch: 28), Train loss: 1.0880, Val loss: 1.1964, Acc: 0.5943, LR: 1.12e-04\n",
            "Step 1440/1500 (Epoch: 28), Train loss: 1.0836, Val loss: 1.1971, Acc: 0.5951, LR: 5.52e-05\n",
            "Step 1470/1500 (Epoch: 29), Train loss: 1.0794, Val loss: 1.1968, Acc: 0.5959, LR: 2.13e-05\n",
            "Completed in 58.90 seconds.\n",
            "\n",
            "Running experiment: xLSTM[1:1], Learning rate = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:546: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, training, *inputs):\n",
            "/usr/local/lib/python3.10/dist-packages/xlstm/blocks/slstm/cell.py:571: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_s):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0000/1500 (Epoch: 1), Train loss: 3.8594, Val loss: 3.8771, Acc: 0.0272, LR: 0.00e+00\n",
            "Step 0030/1500 (Epoch: 1), Train loss: 3.3388, Val loss: 2.7420, Acc: 0.1484, LR: 3.00e-04\n",
            "Step 0060/1500 (Epoch: 2), Train loss: 2.8657, Val loss: 2.2347, Acc: 0.2189, LR: 6.00e-04\n",
            "Step 0090/1500 (Epoch: 2), Train loss: 2.5680, Val loss: 1.9479, Acc: 0.2703, LR: 9.00e-04\n",
            "Step 0120/1500 (Epoch: 3), Train loss: 2.3555, Val loss: 1.7879, Acc: 0.3101, LR: 1.00e-03\n",
            "Step 0150/1500 (Epoch: 3), Train loss: 2.2010, Val loss: 1.6675, Acc: 0.3424, LR: 9.97e-04\n",
            "Step 0180/1500 (Epoch: 4), Train loss: 2.0839, Val loss: 1.5992, Acc: 0.3674, LR: 9.92e-04\n",
            "Step 0210/1500 (Epoch: 5), Train loss: 1.9905, Val loss: 1.5500, Acc: 0.3883, LR: 9.85e-04\n",
            "Step 0240/1500 (Epoch: 5), Train loss: 1.9146, Val loss: 1.5025, Acc: 0.4057, LR: 9.76e-04\n",
            "Step 0270/1500 (Epoch: 6), Train loss: 1.8519, Val loss: 1.4763, Acc: 0.4202, LR: 9.64e-04\n",
            "Step 0300/1500 (Epoch: 6), Train loss: 1.7988, Val loss: 1.4481, Acc: 0.4328, LR: 9.51e-04\n",
            "Step 0330/1500 (Epoch: 7), Train loss: 1.7531, Val loss: 1.4291, Acc: 0.4437, LR: 9.36e-04\n",
            "Step 0360/1500 (Epoch: 7), Train loss: 1.7128, Val loss: 1.4119, Acc: 0.4532, LR: 9.18e-04\n",
            "Step 0390/1500 (Epoch: 8), Train loss: 1.6773, Val loss: 1.3943, Acc: 0.4619, LR: 8.99e-04\n",
            "Step 0420/1500 (Epoch: 9), Train loss: 1.6458, Val loss: 1.3927, Acc: 0.4695, LR: 8.78e-04\n",
            "Step 0450/1500 (Epoch: 9), Train loss: 1.6176, Val loss: 1.3689, Acc: 0.4764, LR: 8.55e-04\n",
            "Step 0480/1500 (Epoch: 10), Train loss: 1.5919, Val loss: 1.3591, Acc: 0.4824, LR: 8.31e-04\n",
            "Step 0510/1500 (Epoch: 10), Train loss: 1.5689, Val loss: 1.3523, Acc: 0.4883, LR: 8.05e-04\n",
            "Step 0540/1500 (Epoch: 11), Train loss: 1.5474, Val loss: 1.3473, Acc: 0.4935, LR: 7.78e-04\n",
            "Step 0570/1500 (Epoch: 11), Train loss: 1.5280, Val loss: 1.3311, Acc: 0.4984, LR: 7.49e-04\n",
            "Step 0600/1500 (Epoch: 12), Train loss: 1.5097, Val loss: 1.3262, Acc: 0.5029, LR: 7.20e-04\n",
            "Step 0630/1500 (Epoch: 13), Train loss: 1.4931, Val loss: 1.3234, Acc: 0.5071, LR: 6.89e-04\n",
            "Step 0660/1500 (Epoch: 13), Train loss: 1.4777, Val loss: 1.3157, Acc: 0.5108, LR: 6.58e-04\n",
            "Step 0690/1500 (Epoch: 14), Train loss: 1.4631, Val loss: 1.3157, Acc: 0.5143, LR: 6.26e-04\n",
            "Step 0720/1500 (Epoch: 14), Train loss: 1.4497, Val loss: 1.3057, Acc: 0.5177, LR: 5.93e-04\n",
            "Step 0750/1500 (Epoch: 15), Train loss: 1.4369, Val loss: 1.3058, Acc: 0.5208, LR: 5.60e-04\n",
            "Step 0780/1500 (Epoch: 16), Train loss: 1.4250, Val loss: 1.3012, Acc: 0.5237, LR: 5.27e-04\n",
            "Step 0810/1500 (Epoch: 16), Train loss: 1.4136, Val loss: 1.2954, Acc: 0.5265, LR: 4.94e-04\n",
            "Step 0840/1500 (Epoch: 17), Train loss: 1.4031, Val loss: 1.2954, Acc: 0.5291, LR: 4.61e-04\n",
            "Step 0870/1500 (Epoch: 17), Train loss: 1.3930, Val loss: 1.2857, Acc: 0.5316, LR: 4.28e-04\n",
            "Step 0900/1500 (Epoch: 18), Train loss: 1.3834, Val loss: 1.2875, Acc: 0.5338, LR: 3.95e-04\n",
            "Step 0930/1500 (Epoch: 18), Train loss: 1.3745, Val loss: 1.2821, Acc: 0.5361, LR: 3.63e-04\n",
            "Step 0960/1500 (Epoch: 19), Train loss: 1.3659, Val loss: 1.2839, Acc: 0.5382, LR: 3.31e-04\n",
            "Step 0990/1500 (Epoch: 20), Train loss: 1.3577, Val loss: 1.2795, Acc: 0.5402, LR: 3.00e-04\n",
            "Step 1020/1500 (Epoch: 20), Train loss: 1.3499, Val loss: 1.2788, Acc: 0.5421, LR: 2.70e-04\n",
            "Step 1050/1500 (Epoch: 21), Train loss: 1.3423, Val loss: 1.2733, Acc: 0.5438, LR: 2.42e-04\n",
            "Step 1080/1500 (Epoch: 21), Train loss: 1.3352, Val loss: 1.2734, Acc: 0.5455, LR: 2.14e-04\n",
            "Step 1110/1500 (Epoch: 22), Train loss: 1.3285, Val loss: 1.2719, Acc: 0.5471, LR: 1.88e-04\n",
            "Step 1140/1500 (Epoch: 22), Train loss: 1.3220, Val loss: 1.2698, Acc: 0.5487, LR: 1.63e-04\n",
            "Step 1170/1500 (Epoch: 23), Train loss: 1.3158, Val loss: 1.2680, Acc: 0.5502, LR: 1.40e-04\n",
            "Step 1200/1500 (Epoch: 24), Train loss: 1.3098, Val loss: 1.2688, Acc: 0.5516, LR: 1.18e-04\n",
            "Step 1230/1500 (Epoch: 24), Train loss: 1.3041, Val loss: 1.2656, Acc: 0.5530, LR: 9.81e-05\n",
            "Step 1260/1500 (Epoch: 25), Train loss: 1.2986, Val loss: 1.2674, Acc: 0.5543, LR: 8.01e-05\n",
            "Step 1290/1500 (Epoch: 25), Train loss: 1.2933, Val loss: 1.2650, Acc: 0.5555, LR: 6.40e-05\n",
            "Step 1320/1500 (Epoch: 26), Train loss: 1.2883, Val loss: 1.2655, Acc: 0.5567, LR: 4.98e-05\n",
            "Step 1350/1500 (Epoch: 26), Train loss: 1.2834, Val loss: 1.2641, Acc: 0.5579, LR: 3.78e-05\n",
            "Step 1380/1500 (Epoch: 27), Train loss: 1.2788, Val loss: 1.2632, Acc: 0.5589, LR: 2.78e-05\n",
            "Step 1410/1500 (Epoch: 28), Train loss: 1.2743, Val loss: 1.2633, Acc: 0.5600, LR: 2.01e-05\n",
            "Step 1440/1500 (Epoch: 28), Train loss: 1.2700, Val loss: 1.2632, Acc: 0.5610, LR: 1.45e-05\n",
            "Step 1470/1500 (Epoch: 29), Train loss: 1.2659, Val loss: 1.2631, Acc: 0.5620, LR: 1.11e-05\n",
            "Completed in 58.83 seconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VISUALIZE EXPERIMENTS\n",
        "\n",
        "# 1 - Learning rates\n",
        "database_name = cfg.database.name\n",
        "db = ExperimentDatabase(db_name=database_name)\n",
        "experiment_ids = [\n",
        "    [\"xLSTM[1:0]_learning_rate_1\", \"xLSTM[1:0]_learning_rate_2\"],\n",
        "    [\"xLSTM[0:1]_learning_rate_3\", \"xLSTM[0:1]_learning_rate_4\"],\n",
        "    [\"xLSTM[1:1]_learning_rate_5\", \"xLSTM[1:1]_learning_rate_6\"]\n",
        "]\n",
        "title = \"Training and validation losses (full lines) at different learning rates\"\n",
        "legend_text = \"LR={config.training.lr}\"\n",
        "plot3_train_val_loss(title, experiment_ids, legend_text, db)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "ogjsR9SHT8fE",
        "outputId": "8e9836d0-0ce4-44d4-b085-35e620ab8c3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVADqjO1A9kI"
      },
      "source": [
        "## Exercise 4: Utilizing a Pretrained Model (Bonus)\n",
        "\n",
        "Foundation Models, those pretrained on large amounts of data are more and more important. We can use those models and fine-tune them on our dataset, rather then training them from scratch.\n",
        "Here are the things to consider:\n",
        "\n",
        "- Model Selection: Choose a pretrained language model from an online repository. Hint: You can explore platforms like Hugging Face (huggingface.co), which host numerous pretrained models.\n",
        "\n",
        "- Dataset: Use the Trump dataset with the same training and validation split as in previous exercises. You do not need to use character tokenization.\n",
        "\n",
        "- Performance Evaluation: Evaluate the performance of the pretrained model on the validation set before and during fine-tuning. Report average-CE-loss as well as an example generated sequence with the same prompt for each epoch.\n",
        "\n",
        "- Fine-tuning: Adjust the learning rate, potentially freeze some layers, train for a few epochs with a framework of your choice (e.g. [lightning](https://lightning.ai/docs/pytorch/stable/), [huggingface](https://huggingface.co/models), ...)\n",
        "\n",
        "- Computational Resources: Be mindful of the computational demands of pretrained models. You might need access to GPUs. Try to keep the model size at a minimum and go for e.g. distilled versions or other small LMs\n",
        "\n",
        "- Hyperparameter Tuning: You can experiment with different learning rates and potentially other hyperparameters during fine-tuning but no need to do this in depth\n",
        "\n",
        "By completing this exercise, you will gain experience with utilizing pretrained models, understanding their capabilities, and the process of fine-tuning. Decreasing the validation loss can be seen a success for this exercise.\n",
        "\n",
        "> **Note**: This is a standalone exercise and doesn't build upon the previous tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqv4tH69Ab0X"
      },
      "outputs": [],
      "source": [
        "########## SOLUTION BEGIN ##########\n",
        "\n",
        "########## YOUR SOLUTION HERE ##########"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}